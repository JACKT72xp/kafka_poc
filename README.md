# ğŸ§© Data Integration PoC with Kafka Connect, DB2 and Oracle using Podman

Este proyecto es una prueba de concepto (PoC) para demostrar una arquitectura de integraciÃ³n de datos entre bases de datos DB2 y Oracle utilizando Apache Kafka, Kafka Connect y conectores JDBC. Todo se despliega utilizando **Podman** y **Podman Compose**, lo que permite una alternativa a Docker para entornos rootless o mÃ¡s seguros.

---

## ğŸ“¦ 1. InstalaciÃ³n de Podman y Podman Compose

### Linux (ejemplo con Ubuntu/Debian)

```bash
sudo apt update && sudo apt install -y podman podman-compose
```

### Validar instalaciÃ³n:

```bash
podman --version
podman-compose --version
```

---

## ğŸ“ 2. Descarga de recursos necesarios

### JARs requeridos (montados en el contenedor Kafka Connect):

- `db2jcc4.jar` â€“ driver JDBC para IBM DB2
- `ojdbc8.jar` â€“ driver JDBC para Oracle (si se desea replicar hacia Oracle)
- Confluent JDBC connector `.jar` (si usas `io.confluent.connect.jdbc.JdbcSourceConnector`)

#### Recomendado: organizar tu carpeta `plugins/` asÃ­:

```bash
plugins/
â””â”€â”€ jdbc/
    â”œâ”€â”€ db2jcc4.jar
    â”œâ”€â”€ ojdbc8.jar
    â”œâ”€â”€ kafka-connect-jdbc-<version>.jar
```

> âš ï¸ AsegÃºrate de que los `.jar` estÃ©n disponibles y se monten correctamente en Kafka Connect.

---

## ğŸ§± 3. Estructura del docker-compose (Podman Compose)

```bash
podman-compose -f docker-compose.yaml up -d
```

### Servicios incluidos:

- **Kafka + Zookeeper** (bitnami o confluent-compatible)
- **Kafka Connect** (usando el conector JDBC y drivers montados)
- **DB2** (imagen oficial `icr.io/db2_community/db2`)
- **Oracle XE** (opcional, si se desea destino)
- **Kafka UI** (opcional, para debug visual)
- **DBeaver** (opcional, para gestionar las DB vÃ­a UI)

---

## âš™ï¸ 4. Scripts de creaciÃ³n y conexiÃ³n

### 1. Conectar a DB2 y crear la base `TESTDB`

La imagen de DB2 puede tardar unos minutos en estar lista. Puedes verificar su estado con:

```bash
podman exec -it db2 bash
su - db2inst1
db2 connect to TESTDB
```

#### Script `db2-init.sql`

```sql
CREATE SCHEMA DEMO;
CREATE TABLE DEMO.CUSTOMERS (
  ID INT NOT NULL GENERATED ALWAYS AS IDENTITY (START WITH 1, INCREMENT BY 1),
  NAME VARCHAR(100),
  EMAIL VARCHAR(100),
  CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (ID)
);
```

> Este script debe ejecutarse manualmente o montarse para ejecuciÃ³n post-inicio.

---

## ğŸ”Œ 5. CreaciÃ³n y validaciÃ³n del conector JDBC

### 1. Verificar que el conector JDBC estÃ© disponible:

```bash
curl -s http://localhost:8083/connector-plugins | jq
```

Busca `io.confluent.connect.jdbc.JdbcSourceConnector`.

---

### 2. Crear el conector vÃ­a POST:

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "test-source-CU-db2-jdbc-autoincrement",
    "config": {
        "bootstrap.servers": "kafka:9092",
        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter",
        "key.converter.schemas.enable": "true",
        "value.converter.schemas.enable": true,
        "offset.storage.file.filename": "/tmp/connect.offsets",
        "offset.flush.interval.ms": 10000,
        "plugin.path": "/kafka/connectors",
        "listeners": "http://0.0.0.0:9092",
        "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
        "tasks.max": "1",
        "connection.url": "jdbc:db2://db2:50000/TESTDB",
        "connection.user": "db2inst1",
        "connection.password": "db2inst1-pwd",
        "dialect.name": "Db2DatabaseDialect",
        "mode": "timestamp+incrementing",
        "incrementing.column.name": "ID",
        "timestamp.column.name": "CHGMARKER",
        "topic.prefix": "test-db2-jdbc-",
        "timestamp.delay.interval.ms": 500,
        "poll.interval.ms": 1000,
        "validate.non.null": false,
        "decimal.format": "NUMERIC",
        "table.types": "TABLE,VIEW",
        "transforms": "InsertKey,ExtractId",
        "transforms.InsertKey.type": "org.apache.kafka.connect.transforms.ValueToKey",
        "transforms.InsertKey.fields": "ID",
        "transforms.ExtractId.type": "org.apache.kafka.connect.transforms.ExtractField$Key",
        "transforms.ExtractId.field": "ID",
        "schema.pattern=DB2INST1": "DB2INST1",
        "table.whitelist": "DB2INST1.EXPEDIENTES,DB2INST1.FONDOS,DB2INST1.ORDENES,DB2INST1.RETENCIONES"
    }
}'
```

En el contenedor del conector db2 vale con hacer:
(Es necesario esperar a que se cree la base de datos db2)

```bash
curl -X POST -H "Content-Type: application/json" --data @/connector_config/db2_connector_config.json http://localhost:8083/connectors
```

### 3. Verificar estado del conector:

```bash
curl -s http://localhost:8083/connectors/db2-source-connector/status | jq
```

> AsegÃºrate de que el estado sea `"RUNNING"` y sin errores de clase JDBC ni fallos de conexiÃ³n.

---

## ğŸ§ª Tips de depuraciÃ³n

- Si ves `"No suitable driver"` revisa que el `.jar` estÃ© en el `volume` y `PLUGIN_PATH`.
- Si ves `"Connection refused"` valida que el contenedor `db2` estÃ© en red y exponga correctamente el puerto.
- Puedes usar `podman exec -it connect bash` y verificar `/kafka/connect/` para confirmar presencia de `.jar`.

---

## ğŸ”š Resultado esperado

Los cambios en la tabla `DEMO.CUSTOMERS` de DB2 deben publicarse en un topic Kafka con nombre `db2-DEMO.CUSTOMERS`.

---

## ğŸ› ï¸ Requisitos mÃ­nimos

- Podman 4.0+
- Podman Compose
- JDK 11+ (en caso de construir plugins manualmente)
- Kafka Connect JDBC 10.7.4 (compatible con DB2)

---

## ğŸ“„ Licencia

Este proyecto es solo para fines de prueba y demostraciÃ³n.
